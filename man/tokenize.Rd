% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenize}
\alias{tokenize_character}
\alias{tokenize_sentence}
\alias{tokenize_fasterword}
\title{quanteda default tokenizer}
\usage{
tokenize(
  x,
  remove_punct = FALSE,
  remove_symbols = FALSE,
  remove_numbers = FALSE,
  remove_url = FALSE,
  preserve_tags = !remove_punct,
  split_infix_hyphens = FALSE,
  ...
)

tokenize_character(x)

tokenize_sentence(x)

tokenize_fasterword(x)
}
\arguments{
\item{x}{a character or \link{corpus} object}

\item{remove_punct}{logical; if \code{TRUE} remove all characters in the Unicode
"Punctuation" \verb{[P]} class, with exceptions for those used as prefixes for
valid social media tags if \code{preserve_tags = TRUE}}

\item{remove_symbols}{logical; if \code{TRUE} remove all characters in the Unicode
"Symbol" \verb{[S]} class}

\item{remove_numbers}{logical; if \code{TRUE} remove tokens that consist only of
numbers, but not words that start with digits, e.g. \verb{2day}}

\item{remove_url}{logical; if \code{TRUE} find and eliminate URLs beginning with
http(s) -- see section "Dealing with URLs".}

\item{preserve_tags}{keep (social media) tags intact, such as "#hashtags" and
"#usernames" even when punctuation will be removed.  The rules defining a
valid "tag" can be found
\href{https://www.hashtags.org/featured/what-characters-can-a-hashtag-include/}{here}
for hashtags and
\href{https://help.twitter.com/en/managing-your-account/twitter-username-rules}{here}
for usernames.}

\item{split_infix_hyphens}{logical; if \code{TRUE} split words that are connected by
hyphenation and hyphenation-like characters in between words, e.g.
\code{"self-aware"} becomes \code{c("self", "-", "aware")}.  Default is \code{FALSE} to
preserve such words as is, with the hyphens.}

\item{...}{not used}
}
\value{
a (uniquely) named list of characters
}
\description{
Default \pkg{quanteda} tokenizer to implement full set of options, for a
character or \link{corpus} input.
}
\examples{
txt <- c(doc1 = "Tweet https://quanteda.io using @quantedainit and #rstats.",
         doc2 = "The £1,000,000 question.",
         doc3 = "毎日 #quanteda を使用してください！")
tokenize(txt)
tokenize(txt, remove_symbols = TRUE, remove_punct = TRUE)
tokenize(txt, remove_symbols = TRUE, remove_punct = TRUE, remove_url = TRUE)
tokenize(txt, remove_symbols = TRUE, remove_punct = TRUE, preserve_tags = TRUE)
tokenize(txt, remove_symbols = FALSE, remove_punct = TRUE, remove_numbers = TRUE)
}
\keyword{tokens}
